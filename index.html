<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>Home | Henk Jekel </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>

</head>

<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper" class="fade-in">

        <!-- Intro -->
        <div id="intro">
            <h1>Henk Jekel<br />
                <p>Robotics engineer
                </p>
                <p>
                    <a href="https://www.linkedin.com/in/henk-jekel-748054259/" target="_blank">
                        <img src="images/linkedin_icon.png" alt="LinkedIn Pictogram" width="35" height="35">
                    </a>
                    <a href="https://www.kaggle.com/hajekel" target="_blank">
                        <img src="images/kaggle_icon.png" alt="Kaggle Pictogram" width="35" height="35">
                    </a>
                    <a href="https://github.com/HAJEKEL" target="_blank">
                        <img src="images/github_icon.png" alt="Github Pictogram" width="35" height="35">
                    </a>
                    <a href="mailto:hendrikjekel@gmail.com" target="_blank">
                        <img src="images/gmail_icon.png" alt="Gmail Pictogram" width="35" height="35">
                    </a>


                </p>
                <ul class="actions">
                    <li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
                </ul>
        </div>

        <!-- Header -->
        <header id="header">
            <a href="index.html" class="logo">Home</a>
        </header>

        <!-- Nav -->
        <nav id="nav">
            <ul class="links">
                <li class="active"><a href="index.html">Projects</a></li>
                <li><a href="generic.html">About</a></li>
                <li><a href="elements.html">Resume</a></li>
            </ul>
            <ul class="icons">
                <li><a href="https://www.linkedin.com/in/henk-jekel-748054259/"
                        class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a>
                </li>
                <li><a href="https://www.kaggle.com/hajekel" class="icon brands fa-kaggle"><span
                            class="label">Kaggle</span></a></li>
                <li><a href="https://github.com/HAJEKEL" class="icon brands alt fa-github"><span
                            class="label">GitHub</span></a></li>
            </ul>
        </nav>

        <!-- Main -->
        <div id="main">

            <!-- Featured Post -->
            <article class="post featured">
                <header class="major">
                    <span class="date">October 30, 2022</span>
                    <h2><a href="#">Autonomous driving<br />
                            ROS</a></h2>
                </header>
                <a href="#" class="image fit"><img src="images/prius_project.png" alt="prius_project" /></a>

                <p>In this university assignment, I developed software for autonomous driving
                    of a Prius vehicle in a simulated test track utilizing the Robot Operating
                    System (ROS). The Prius was equipped with two primary sensors, a front-facing
                    camera located behind the windshield and a 360-degree top-mounted LIDAR sensor.
                    The vehicle's system received the camera images and LIDAR point clouds as ROS topics.
                </p>

                <p>
                    The objective of this study was to design a virtual, controllable Prius vehicle that could
                    detect obstacles and pedestrians using its sensors, and subsequently maneuver autonomously along
                    a path defined by cones, avoiding all obstacles. Additionally, the vehicle was required to stop
                    in the presence of pedestrians.
                </p>
                <p>
                    For this study, the university supplied a simulation platform comprised of a virtual vehicle and
                    environment. To accomplish the autonomous driving task, we implemented three additional ROS
                    packages as the solution.
                </p>
                <div class="row">


                    <ul>
                        <li>As part of the solution, we created an "opencv_person_detector" package that contained a
                            node capable of detecting 2D bounding boxes around all individuals in a camera image
                            through
                            the use of OpenCV.</li>
                        <li>Additionally, we developed a "pcl_obstacle_detector" package that included a node for
                            detecting 3D bounding boxes around all barrels present in the LIDAR point cloud through
                            the
                            use of Point Cloud Library (PCL).</li>
                        <li>Finally, we created a "control_barrel_world" package that comprised a node responsible
                            for
                            controlling the vehicle. This node subscribed to both the 3D barrel detections and 2D
                            person
                            detections, and published control messages to drive the vehicle.</li>

                    </ul>

                </div>
                <p>
                    The accompanying illustration showcases the topics and nodes incorporated in the solution.
                </p>
                <a href="#" class="image fit"><img src="images/prius_solution.png" alt="prius_project" /></a>

                <p>The source code for this project must be kept confidential. A recording of the functioning simulation
                    after the implementation of the solution is provided below, albeit with some lag in the display due
                    to the GIF format.</p>
                <a href="#" class="image fit"><img src="images/prius_project.gif" alt="prius_project" /></a>


                <ul class="actions special">
                    <li><a href="#" class="button large">View project</a></li>
                </ul>

            </article>
            There are some commented-out code blocks that contain alternative models (DenseNet-169, DenseNet-121) and
            training configurations for different datasets.


            <!-- Posts -->
            <article class="posts">
            </section>
                <article>
                    <header>
                        <span class="date">Januari 20, 2022</span>
                        <h2><a>RRT* motion planning<br />
                                for a mobile robot<br />
                                in a Parking lot scenario</a></h2>
                    </header>
                    <a class="image fit"><img src="images/rrt_.gif" alt="" /></a>
                    <p>Both the RRT and RRT* single query path planning algorithms were implemented for a mobile robot
                        in a parking lot scenario without utilizing a planner module, and their results were analyzed.
                        The robot, represented through a kinematic bicycle model, was able to follow the computed path
                        with the assistance of a PD controller. The simulation was conducted using the Pygame platform.
                    </p>
                    <ul class="actions special">
                        <li><a href="website" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">November 10, 2023</span>
                        <h2><a>Adaptive AI VoiceTrainer:<br />
                            Enhancing Sales Training Efficiency with Adaptive AI Interactive Voice Response System</a></h2>
                    </header>
                    <a class="image fit"><img src="images/cover.png" alt="" /></a>
                    <p>This project introduces an adaptive AI phone application developed for KLM, aimed at revolutionizing the training of sales representatives. Utilizing advanced artificial intelligence within a systems-engineered framework, the application facilitates realistic and effective training scenarios. The project commenced with the conceptualization and enactment of an abstract usage scenario, further broken down into detailed deployment and operational phases. Key features include VOIP integration, speech-to-text and text-to-speech conversions, and AI-driven response generation, all meticulously delineated in a functional hierarchy tree and activity diagrams. The iterative development process prioritized real-time interaction, low latency, and high-quality voice output, culminating in an integrated system combining Vosk, ElevenLabs, ChatGPT 4, and Twilioâ€™s Voice API. This innovative system is designed to enhance the training experience, preparing sales representatives to confidently navigate the complexities of unpredictable real-life customer interactions.</p>
                    <ul class="actions special">
                        <li><a href="https://hajekel.github.io/ai-flight-innovators-js-stream-app" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">may 2, 2023</span>
                        <h2><a >Effects of time delay<br /> on the 
                            performance of a<br /> deep sea welding task</a></h2>
                    </header>
                    <a class="image fit"><img src="images/demo.gif" alt="" /></a>
                    <p>This study evaluates the effect of time delay on the performance of a teleoperated robot arm in simulated deep sea welding tasks. Given the hazardous nature of deep sea welding, the research explores a safer alternative using teleoperation. The experiment involved 10 participants controlling a robot arm to follow a set trajectory under varying time delays. Performance was measured using mean absolute error and task completion time. Results show a significant increase in both metrics with increased time delays, indicating a decline in operational efficiency. The study highlights the challenges of latency in teleoperated systems and suggests avenues for future research, including the impact of training and trajectory learning on performance.</p>
                    <ul class="actions special">
                        <li><a href="https://hajekel.github.io/teleoperation-delay" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">Date</span>
                        <h2><a>Automated retail store restocking<br />
                            using PDDL and ROSPlan</a></h2>
                    </header>
                    <a class="image fit"><img src="images/picknplace.gif" alt="" /></a>
                    <p>This project presents an automated solution for retail store restocking using PDDL (Planning Domain Definition Language) and ROSPlan, led by Henk Jekel. It aims to address labor shortages in the retail sector due to an aging population. The system enables a robot to perform restocking tasks in a simulated store environment, determining the appropriate placement of items based on predefined store rules. The solution uses a Python-based ontology for product classification and a PDDL knowledge base for initial environment setup. Despite facing technical challenges in simulation, the project demonstrates the feasibility of using knowledge representation and reasoning for efficient and adaptable automated restocking in retail settings.</p>
                    <ul class="actions special">
                        <li><a href="https://hajekel.github.io/Automated-retail-store" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">Date</span>
                        <h2><a>Drone<br />
                                Projects</a></h2>
                    </header>
                    <a class="image fit"><img src="images/pic07.jpg" alt="" /></a>
                    <p>Future Projects</p>
                    <ul class="actions special">
                        <li><a href="#" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">April 28, 2023</span>
                        <h2><a>EFFICIENTNETV2
                            </a></h2>
                        <h3>DARTS FOR NEURAL ARCHITECTURE SEARCH</h3>
                    </header>
                    <a class="image fit"><img
                            src="images/reduce.gif" alt="" /></a>
                    <p>In this project, I developed software to utilize differentiable architecture search (DARTS) for
                        determining the best building block for a cell. Specifically, I compared three types of blocks:
                        Fused-MBConv, MBConv, and Depthwise Separable Convolution. The motivation behind the project was
                        to investigate the developmental process of the Fused-MBConv block, which is a superior
                        architecture building block used in the state-of-the-art image recognizer, EfficientNetV2,
                        developed by the Google brain team. I conducted a differentiable architecture search to evaluate
                        the performance of these three blocks on the Fashion-MNIST dataset. My research aimed to prove
                        that the DARTS algorithm would choose the best block among the three types that were evaluated.
                        However, the findings indicated that for the reduce cell, the algorithm found a mixture of
                        blocks, and for the normal cell, it only used the weakest block, which is the Depthwise
                        Separable Convolution, for unknown reasons.</p>
                    <ul class="actions special">
                        <li><a href="https://hajekel.github.io/EfficientNetV2_paper_reproduction/" class="button">View
                                Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">May 21, 2023</span>
                        <h2><a href="https://hajekel.github.io/BrightSight/">BrightSight<br />
                            </a></h2>
                        <h3> UNLOCKING THE VISUAL WORLD: HARNESSING THE LOTTERY TICKET HYPOTHESIS FOR
                            STATE-OF-THE-ART MONOCULAR DEPTH ESTIMATION IN EMBEDDED GLASSES TO EMPOWER THE VISUALLY
                            IMPAIRED.</h3>
                    </header>
                    <a class="image fit"><img
                            src="images/brightsight_implementation.png" alt="" /></a>
                    <p>In this research, I introduce a method to compress state-of-the-art depth estimators using the
                        lottery ticket hypothesis. My objective is to enable real-time depth estimation on embedded
                        glasses, thereby facilitating safe navigation for visually impaired individuals. By employing
                        transformer backbones instead of convolutional networks, my proposed approach, MiDaS v3.0 DPT-L,
                        revolutionizes dense vision estimation. However, I encountered challenges in directly
                        implementing MiDaS or Adabins on embedded glasses, such as low FPS on single board computers.
                        The main motivation behind this project is to empower visually impaired individuals to navigate
                        unfamiliar environments and avoid obstacles. As a proof of concept, I implemented the pruned
                        model on a Raspberry Pi Model 3B. The model determines the optimal steering angle by analyzing a
                        horizontal strip of average bins and evaluating three criteria based on the generated depth map.
                        My research aims to demonstrate the feasibility of incorporating haptic feedback for obstacle
                        avoidance into existing glasses for the visually impaired, utilizing their single board computer
                        monocular camera products. The experimental results I obtained demonstrate that achieving an FPS
                        of 20 is feasible. MiDaS exhibits the most promising performance due to its higher accuracy at
                        this frame rate, thereby highlighting the potential for enhancing the functionality of glasses
                        for the visually impaired.</p>
                    <ul class="actions special">
                        <li><a href="#" class="https://hajekel.github.io/BrightSight/">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">June 16, 2023</span>
                        <h2><a >The lottery tickets hypohtesis for<br />
                                supervised pre-training in depth estimation.
                            </a></h2>
                    </header>
                    <a  class="image fit"><img src="images/transfer_learning_LTH_depth.png" alt="" /></a>
                    <p>Abstract: In the field of computer vision, pre-trained models have gained renewed attention,
                        including ImageNet supervised pre-training. Recent studies have highlighted the enduring
                        significance of the Lottery Tickets Hypothesis (LTH) in the context of classification,
                        detection, and segmentation tasks. Inspired by this, we set out to explore the potential of LTH
                        in the pre-training paradigm of depth estimation. Our aim is to investigate whether we can
                        significantly reduce the complexity of pre-trained models without compromising their downstream
                        transferability in the depth estimation task. We fine-tune the sparse pre-trained networks
                        obtained through iterative magnitude pruning and demonstrate universal transferability to the
                        depth estimation task, maintaining performance comparable to that of fine tuning on the full
                        pre-trained model. Our findings are still inconclusive. </p>
                    <ul class="actions special">
                        <li><a href="https://hajekel.github.io/CV_LTH_pre-training_depth-estimation/"
                                class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">July 1, 2023</span>
                        <h2><a>Albert: The Next-Gen Supermarket Assistant<br /> Integrating Advanced AI for Seamless In-Store and Online Order Fulfillment
                            </a></h2>
                    </header>
                    <a  class="image fit"><img src="images/presentproduct.jpg"  alt="" /></a>
                    <p>The Albert project developed a versatile robotic system for supermarkets, designed to handle both online and in-store customer orders. Featuring an advanced ChatGPT-powered voice interaction system, Albert efficiently processes and responds to customer requests. Its autonomous capabilities include identifying, picking, and placing products, managed by the FlexBE state machine. Equipped with sensors like lidar and stereo cameras, it navigates safely around obstacles and customers. While testing has shown promising results in both simulations and real-world scenarios, further refinement is necessary to address remaining challenges before widespread implementation in supermarkets.</p>
                    <ul class="actions special">
                        <li><a href="#" class="button">View Project</a></li>
                    </ul>
                </article>
                <article>
                    <header>
                        <span class="date">Date</span>
                        <h2><a>Future<br />
                                Projects</a></h2>
                    </header>
                    <a lass="image fit"><img src="images/pic07.jpg" alt="" /></a>
                    <p>Future Projects</p>
                    <ul class="actions special">
                        <li><a href="#" class="button">View Project</a></li>
                    </ul>
                </article>
            </section>

            <!-- Footer -->
            <footer>
                <div class="pagination">
                    <!--<a href="#" class="previous">Prev</a>-->
                    <a href="#" class="page active">1</a>
                    <a href="#" class="page">2</a>
                    <a href="#" class="page">3</a>
                    <span class="extra">&hellip;</span>
                    <a href="#" class="page">8</a>
                    <a href="#" class="page">9</a>
                    <a href="#" class="page">10</a>
                    <a href="#" class="next">Next</a>
                </div>
            </footer>

        </div>

        <!-- Footer -->
        <footer id="footer">

            <section class="split contact">
                <section class="alt">
                    <h3>Address</h3>
                    <p>Delft, Netherlands<br />
                </section>

                <section>
                    <h3>Email</h3>
                    <p><a href="#">hendrikjekel@gmail.com</a></p>
                </section>
                <section>
                    <h3>Social</h3>
                    <ul class="icons">
                        <li><a href="https://www.linkedin.com/in/henk-jekel-748054259/"
                                class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a>
                        </li>
                        <li><a href="https://www.kaggle.com/hajekel" class="icon brands fa-kaggle"><span
                                    class="label">Kaggle</span></a></li>
                        <li><a href="https://github.com/HAJEKEL" class="icon brands alt fa-github"><span
                                    class="label">GitHub</span></a></li>
                    </ul>
                </section>
            </section>
        </footer>

        <!-- Copyright -->
        <div id="copyright">
            <ul>
                <li>Henk Jekel &copy; 2022</li>
                <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
            </ul>
        </div>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>